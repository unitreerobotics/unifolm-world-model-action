# UnifoLM-WMA-0: A World-Model-Action (WMA) Framework under UnifoLM Family
 <p style="font-size: 1.2em;">
    <a href="https://unigen-x.github.io/unifolm-world-model-action.github.io"><strong>é¡¹ç›®ä¸»é¡µ</strong></a> | 
    <a href="https://huggingface.co/collections/unitreerobotics/unifolm-wma-0-68ca23027310c0ca0f34959c"><strong>å¼€æºæ¨¡å‹</strong></a> |
    <a href="https://huggingface.co/unitreerobotics/datasets"><strong>å¼€æºæ•°æ®</strong></a> 
  </p>
<div align="center">
  <p align="right">
    <span> ğŸŒEnglish </span> | <a href="README_cn.md"> ğŸ‡¨ğŸ‡³ä¸­æ–‡ </a>
  </p>
</div>

**UnifoLM-WMA-0** æ˜¯å®‡æ ‘ç§‘æŠ€è·¨å¤šç±»æœºå™¨äººæœ¬ä½“çš„å¼€æºä¸–ç•Œæ¨¡å‹-åŠ¨ä½œæ¶æ„ï¼Œä¸“ä¸ºé€šç”¨æœºå™¨äººå­¦ä¹ è€Œè®¾è®¡ã€‚å…¶æ ¸å¿ƒæˆåˆ†åœ¨äºä¸€ä¸ªå¯ä»¥ç†è§£æœºå™¨äººä¸ç¯å¢ƒäº¤äº’ç‰©ç†è§„å¾‹çš„ä¸–ç•Œæ¨¡å‹ã€‚è¯¥ä¸–ç•Œæ¨¡å‹å…·å¤‡ä¸¤å¤§æ ¸å¿ƒåŠŸèƒ½ï¼šï¼ˆ1ï¼‰**ä»¿çœŸå¼•æ“**ï¼Œä½œä¸ºäº¤äº’å¼ä»¿çœŸå™¨è¿è¡Œï¼Œä¸ºæœºå™¨äººå­¦ä¹ æä¾›åˆæˆæ•°æ®;ï¼ˆ2ï¼‰**ç­–ç•¥å¢å¼º**ï¼Œå¯ä¸ä¸€ä¸ªåŠ¨ä½œå¤´è¿›è¡Œå¯¹æ¥ï¼Œé€šè¿‡é¢„æµ‹æœªæ¥ä¸ç‰©ç†ä¸–ç•Œçš„äº¤äº’è¿‡ç¨‹ï¼Œè¿›ä¸€æ­¥ä¼˜åŒ–å†³ç­–æ€§èƒ½ã€‚æ¨¡å‹çš„çœŸæœºéƒ¨ç½²æ•ˆæœå¦‚ä¸‹æ‰€ç¤ºï¼Œå…¶ä¸­å³ä¸Šè§’å°çª—å£æ˜¯ä¸–ç•Œæ¨¡å‹å¯¹äºæœªæ¥ç¯å¢ƒå˜åŒ–çš„é¢„æµ‹ï¼Œå¯è¾…åŠ©æ§åˆ¶æŒ‡ä»¤ç”Ÿæˆã€‚

## ğŸ¦¾ çœŸæœºæ•ˆæœ 

| <img src="assets/gifs/real_z1_stackbox.gif" style="border:none;box-shadow:none;margin:0;padding:0;" /> | <img src="assets/gifs/real_dual_stackbox.gif" style="border:none;box-shadow:none;margin:0;padding:0;" /> |
|:---:|:---:|
| <img src="assets/gifs/real_cleanup_pencils.gif" style="border:none;box-shadow:none;margin:0;padding:0;" /> | <img src="assets/gifs/real_g1_pack_camera.gif" style="border:none;box-shadow:none;margin:0;padding:0;" /> |

**æ³¨ï¼šå³ä¸Šè§’å°çª—å£æ˜¾ç¤ºä¸–ç•Œæ¨¡å‹å¯¹æœªæ¥åŠ¨ä½œè§†é¢‘çš„é¢„æµ‹ã€‚**

## æ–°é—»
* 2025å¹´9æœˆ15æ—¥: ğŸš€ æˆ‘ä»¬å‘å¸ƒäº† **UnifoLM-WMA-0** çš„è®­ç»ƒä¸æ¨ç†ä»£ç ï¼Œä»¥åŠå¯¹åº”çš„æ¨¡å‹æƒé‡.


## ğŸ“‘ å¼€æºè®¡åˆ’
- [x] è®­ç»ƒä»£ç  
- [x] æ¨ç†ä»£ç  
- [x] æ¨¡å‹Checkpoints
- [x] çœŸæœºéƒ¨ç½²ä»£ç 

## âš™ï¸  å®‰è£…
```
conda create -n unifolm-wma python==3.10.18
conda activate unifolm-wma

conda install pinocchio=3.2.0 -c conda-forge -y
conda install ffmpeg=7.1.1 -c conda-forge

git clone --recurse-submodules https://github.com/unitreerobotics/unifolm-world-model-action.git

# If you already downloaded the repo:
cd unifolm-world-model-action
git submodule update --init --recursive

pip install -e .

cd external/dlimp
pip install -e .
```
## ğŸ§° æ¨¡å‹ Checkpoints
| æ¨¡å‹ | æè¿° | é“¾æ¥ |
|---------|-------|------|
|$\text{UnifoLM-WMA-0}_{Base}$| åœ¨ [Open-X](https://robotics-transformer-x.github.io/) æ•°æ®é›†å¾®è°ƒåçš„æ¨¡å‹ | [HuggingFace](https://huggingface.co/unitreerobotics/UnifoLM-WMA-0-Base)|
|$\text{UnifoLM-WMA-0}_{Dual}$| åœ¨äº”ä¸ª[å®‡æ ‘ç§‘æŠ€å¼€æºæ•°æ®é›†](https://huggingface.co/collections/unitreerobotics/g1-dex1-datasets-68bae98bf0a26d617f9983ab)ä¸Šï¼Œå†³ç­–å’Œä»¿çœŸåŒæ¨¡å¼ï¼Œè”åˆå¾®è°ƒåçš„æ¨¡å‹ | [HuggingFace](https://huggingface.co/unitreerobotics/UnifoLM-WMA-0-Dual)|

## ğŸ›¢ï¸ æ•°æ®é›†
å®éªŒä¸­ï¼Œæˆ‘ä»¬è®­ç»ƒæµ‹è¯•äº†å¦‚ä¸‹äº”ä¸ªå¼€æºæ•°æ®é›†ï¼š
| æ•°æ®é›† | æœºå™¨äºº | é“¾æ¥ |
|---------|-------|------|
|Z1_StackBox| [Unitree Z1](https://www.unitree.com/z1)|[Huggingface](https://huggingface.co/datasets/unitreerobotics/Z1_StackBox_Dataset/tree/v2.1)|
|Z1_DualArm_StackBox|[Unitree Z1](https://www.unitree.com/z1)|[Huggingface](https://huggingface.co/datasets/unitreerobotics/Z1_Dual_Dex1_StackBox_Dataset/tree/v2.1)|
|Z1_DualArm_StackBox_V2|[Unitree Z1](https://www.unitree.com/z1)|[Huggingface](https://huggingface.co/datasets/unitreerobotics/Z1_Dual_Dex1_StackBox_Dataset_V2/tree/v2.1)|
|Z1_DualArm_Cleanup_Pencils|[Unitree Z1](https://www.unitree.com/z1)|[Huggingface](https://huggingface.co/datasets/unitreerobotics/Z1_Dual_Dex1_CleanupPencils_Dataset/tree/v2.1)|
|G1_Pack_Camera|[Unitree G1](https://www.unitree.com/g1)|[Huggingface](https://huggingface.co/datasets/unitreerobotics/G1_Dex1_MountCameraRedGripper_Dataset/tree/v2.1)|

è¦åœ¨è‡ªå®šä¹‰æ•°æ®é›†ä¸Šè®­ç»ƒï¼Œè¯·é¦–å…ˆç¡®ä¿æ•°æ®ç¬¦åˆ [Huggingface LeRobot V2.1](https://github.com/huggingface/lerobot)  æ•°æ®é›†æ ¼å¼ï¼Œå‡è®¾ä¸‹è½½åçš„æ•°æ®ç›®å½•ç»“æ„å¦‚ä¸‹ï¼š
```
source_dir/
    â”œâ”€â”€ dataset1_name
    â”œâ”€â”€ dataset2_name
    â”œâ”€â”€ dataset3_name
    â””â”€â”€ ...
```
éšåæ‰§è¡Œä»¥ä¸‹å‘½ä»¤è¿›è¡Œæ ¼å¼è½¬æ¢:
```python
cd prepare_data
python prepare_training_data.py \
    --source_dir /path/to/your/source_dir \
    --target_dir /path/to/save/the/converted/data/directory \
    --dataset_name "dataset1_name" \
    --robot_name "a tag of the robot in the dataset" # ä¾‹å¦‚ï¼š Unitree Z1 Robot Arm æˆ– Unitree G1 Robot with Gripperã€‚
```
è½¬æ¢åçš„æ•°æ®ç»“æ„å¦‚ä¸‹ï¼ˆæ³¨ï¼šæ¨¡å‹è®­ç»ƒåªæ”¯æŒä¸»è§†è§’ç›¸æœºè¾“å…¥ï¼Œ å¦‚æ•°æ®å­˜åœ¨è…•éƒ¨è§†è§’ï¼Œéœ€åˆ é™¤CSVæ–‡ä»¶ä¸­```data_dir```åˆ—å¯¹åº”çš„è§†é¢‘è·¯å¾„ï¼‰ï¼š
```
target_dir/
    â”œâ”€â”€ videos
    â”‚     â”œâ”€â”€dataset1_name
    â”‚     â”‚   â”œâ”€â”€camera_view_dir
    â”‚     â”‚       â”œâ”€â”€ 0.mp4
    â”‚     â”‚       â”œâ”€â”€ 1.mp4
    â”‚     â”‚       â””â”€â”€ ...
    â”‚     â””â”€â”€ ...
    â”œâ”€â”€ transitions
    â”‚    â”œâ”€â”€ dataset1_name
    â”‚    â”‚   â”œâ”€â”€ meta_data
    â”‚    â”‚   â”œâ”€â”€ 0.h5
    â”‚    â”‚   â”œâ”€â”€ 1.h5
    â”‚    â”‚   â””â”€â”€ ...
    â”‚    â””â”€â”€ ...
    â””â”€â”€  dataset1_name.csv
```
## ğŸš´ â™‚ï¸ æ¨¡å‹è®­ç»ƒ
ä¸€. æˆ‘ä»¬çš„è®­ç»ƒç­–ç•¥æ¦‚æ‹¬å¦‚ä¸‹ï¼š
- **æ­¥éª¤ 1**ï¼šåœ¨ [Open-X](https://robotics-transformer-x.github.io/) æ•°æ®é›†ä¸Šå¾®è°ƒè§†é¢‘ç”Ÿæˆæ¨¡å‹ï¼Œä½¿å…¶ä½œä¸ºä¸–ç•Œæ¨¡å‹ï¼ˆWorld Modelï¼‰ï¼›
- **æ­¥éª¤ 2**ï¼šåœ¨ä¸‹æ¸¸ä»»åŠ¡æ•°æ®é›†ä¸Šï¼Œå¯¹ $\text{UnifoLM-WMA}$ è¿›è¡Œå†³ç­–æ¨¡å¼ï¼ˆdecision-making modeï¼‰åè®­ç»ƒï¼›
  <div align="left">
   <img src="assets/pngs/dm_mode.png" width="600">
  </div>
- **æ­¥éª¤ 3**ï¼šåœ¨ä¸‹æ¸¸ä»»åŠ¡æ•°æ®é›†ä¸Šï¼Œå¯¹ $\text{UnifoLM-WMA}$ è¿›è¡Œä»¿çœŸæ¨¡å¼ï¼ˆsimulation modeï¼‰åè®­ç»ƒã€‚
  <div align="left">
   <img src="assets/pngs/sim_mode.png" width="600">
  </div>
**æ³¨æ„**ï¼šå¦‚æœåªéœ€è¦ $\text{UnifoLM-WMA}$ åœ¨å•ä¸€æ¨¡å¼ä¸‹è¿è¡Œï¼Œå¯ä»¥è·³è¿‡ç›¸åº”çš„æ­¥éª¤ã€‚

äºŒ. åœ¨å•ä¸ªæˆ–å¤šä¸ªæ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒï¼Œè¯·æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤æ“ä½œï¼š
- **æ­¥éª¤1**ï¼šé»˜è®¤çš„æœ€é«˜è‡ªç”±åº¦ä¸º16DOFï¼Œè‹¥éœ€æ›´å¤šè‡ªç”±åº¦ï¼Œè¯·ä¿®æ”¹[configs/train/config.yaml](https://github.com/unitreerobotics/unifolm-wma/blob/working/configs/train/config.yaml) ä¸­ ```agent_state_dim``` åŠ ```agent_action_dim``` çš„æ•°å€¼ï¼›
- **æ­¥éª¤2**ï¼šåœ¨ [configs/train/meta.json](https://github.com/unitreerobotics/unitree-world-model/blob/main/configs/train/meta.json) ä¸­ä¸ºæ¯ç§æ¨¡æ€è®¾ç½®è¾“å…¥ç»´åº¦ï¼›
- **æ­¥éª¤3**ï¼š åœ¨ [configs/train/config.yaml](https://github.com/unitreerobotics/unitree-world-model/blob/main/configs/train/config.yaml) ä¸­é…ç½®è®­ç»ƒå‚æ•°åŠè·¯å¾„ã€‚å…³äºé¢„è®­ç»ƒçš„æ¨¡å‹ï¼Œæ¨èä½¿ç”¨ $\text{UnifoLM-WMA-0}_{Base}$ ï¼Œå…¶åœ¨[Open-X](https://robotics-transformer-x.github.io/) æ•°æ®é›†ä¸Šå¾®è°ƒè¿‡ï¼›
  ```yaml
  model:
      pretrained_checkpoint: /path/to/pretrained/checkpoint
      ...
      dicision_making_only: True # æ˜¯å¦åªè®­ç»ƒä¸–ç•Œæ¨¡å‹å†³ç­–æ¨¡å¼ï¼Ÿå¦‚æœå¦ï¼Œåˆ™å†³ç­–æ¨¡å¼ä¸ä»¿çœŸæ¨¡å¼è”åˆè®­ç»ƒã€‚
      ...
  data:
      ...
      train:
          ...
          data_dir: /path/to/training/dataset/directory
      dataset_and_weights: # åˆ—å‡ºæ‰€æœ‰æ•°æ®é›†çš„åç§°åŠæƒé‡ï¼Œç¡®ä¿æƒé‡å’Œä¸º1.0
          dataset1_name: 0.2
          dataset2_name: 0.2
          dataset3_name: 0.2
          dataset4_name: 0.2
          dataset5_name: 0.2
  ```
- **æ­¥éª¤4**ï¼š åœ¨ [scripts/train.sh](https://github.com/unitreerobotics/unitree-world-model/blob/main/scripts/train.sh) ä¸­é…ç½®```experiment_name```, ```save_root``` å˜é‡ï¼›
- **æ­¥éª¤5**ï¼š è¿è¡Œå¦‚ä¸‹æŒ‡ä»¤å¼€å¯è®­ç»ƒï¼š
```
bash scripts/train.sh
```
## ğŸŒ ä¸–ç•Œæ¨¡å‹äº¤äº’æ¨ç†
è¦å¯ç”¨ä¸–ç•Œæ¨¡å‹çš„äº¤äº’æ¨¡å¼ï¼Œè¯·æŒ‰ä»¥ä¸‹æ­¥éª¤æ“ä½œï¼š
- **æ­¥éª¤1**ï¼š(è‹¥ä»…ç”¨æä¾›çš„å®ä¾‹è¿›è¡Œæµ‹è¯•ï¼Œå¯è·³è¿‡æ­¤æ­¥) è¯·æŒ‰ç…§ [examples/world_model_interaction_prompts](https://github.com/unitreerobotics/unitree-world-model/tree/main/examples/world_model_interaction_prompts) ç›®å½•ä¸­çš„æ ¼å¼ï¼Œè‡ªå®šä¹‰æç¤ºè¯ç›®å½•ï¼š
```
world_model_interaction_prompts/
    â”œâ”€â”€ images
    â”‚    â”œâ”€â”€ dataset1_name
    â”‚    â”‚       â”œâ”€â”€ 0.png     # å›¾åƒæç¤ºè¯
    â”‚    â”‚       â””â”€â”€ ...
    â”‚    â””â”€â”€ ...
    â”œâ”€â”€ transitions
    â”‚    â”œâ”€â”€ dataset1_name
    â”‚    â”‚       â”œâ”€â”€ meta_data # ç”¨äºå½’ä¸€åŒ–
    â”‚    â”‚       â”œâ”€â”€ 0.h       # æœºå™¨äººçŠ¶æ€ã€åŠ¨ä½œç›¸å…³æ•°æ®ï¼Œåœ¨äº¤äº’æ¨¡å¼ä¸‹ä»…ç”¨äºè·å–ä¸å›¾åƒæç¤ºè¯å¯¹åº”çš„æœºå™¨äººçŠ¶æ€
    â”‚    â”‚       â””â”€â”€ ...
    â”‚    â””â”€â”€ ...
    â”œâ”€â”€  dataset1_name.csv     # è¯¥æ–‡ä»¶ç”¨äºåŠ è½½å¯¹åº”çš„ï¼šå›¾åƒæç¤ºè¯ã€æ–‡æœ¬æŒ‡ä»¤åŠæœºå™¨äººçŠ¶æ€
    â””â”€â”€ ...
```
- **æ­¥éª¤2**ï¼š åœ¨ [configs/inference/world_model_interaction.yaml](https://github.com/unitreerobotics/unitree-world-model/blob/main/configs/inference/world_model_interaction.yaml) ä¸­æŒ‡å®š ```pretrained_checkpoint``` (ä¾‹å¦‚ï¼š$\text{UnifoLM-WMA-0}_{Dual}$) å’Œ ```data_dir``` çš„æ­£ç¡®è·¯å¾„ï¼›
- **æ­¥éª¤3**ï¼š åœ¨ [scripts/run_world_model_interaction.sh](https://github.com/unitreerobotics/unitree-world-model/blob/main/scripts/run_world_model_interaction.sh) ä¸­æŒ‡å®š```checkpoint```ã€```res_dir``` å’Œ ```prompt_dir```çš„æ­£ç¡®è·¯å¾„ï¼Œå¹¶åœ¨```datasets=(...)```ä¸­åˆ—å‡ºæµ‹è¯•çš„æ•°æ®é›†åç§°ï¼Œç„¶åç”¨ä¸‹è¿°æŒ‡ä»¤å¯åŠ¨æ¨ç†:
    ```
    bash scripts/run_world_model_interaction.sh
    ```
  
## ğŸ§  ä¸–ç•Œæ¨¡å‹å†³ç­–æ¨ç†åŠéƒ¨ç½²
åœ¨æˆ‘ä»¬çš„ç³»ç»Ÿä¸­ï¼Œæ¨ç†åœ¨æœåŠ¡å™¨ç«¯æ‰§è¡Œï¼›æœºå™¨äººå®¢æˆ·ç«¯ä»çœŸå®æœºå™¨äººæ”¶é›†è§‚æµ‹ä¿¡æ¯å¹¶å‘é€è‡³æœåŠ¡å™¨, è¿›è¡Œè§†é¢‘åŠåŠ¨ä½œæ¨ç†ã€‚å¯é€šè¿‡å¦‚ä¸‹æ­¥éª¤å®ç°æ•´ä¸ªè¿‡ç¨‹ï¼š

### æœåŠ¡å™¨ç«¯è®¾ç½®
- **æ­¥éª¤1**ï¼š åœ¨ [scripts/run_real_eval_server.sh](https://github.com/unitreerobotics/unifolm-world-model-action/blob/main/scripts/run_real_eval_server.sh) ä¸­æŒ‡å®š ```ckpt```ã€```res_dir```ã€```datasets```;
- **æ­¥éª¤2**ï¼š åœ¨ [config/inference/world_model_decision_making.yaml](https://github.com/unitreerobotics/unifolm-world-model-action/blob/f12b4782652ca00452941d851b17446e4ee7124a/configs/inference/world_model_decision_making.yaml#L225) ä¸­é…ç½® ```data_dir``` å’Œ ```dataset_and_weights```;
- **æ­¥éª¤3**ï¼š å¯åŠ¨æœåŠ¡å™¨ï¼š
```
conda activate unifolm-wma
cd unifolm-world-model-action
bash scripts/run_real_eval_server.sh
```

### å®¢æˆ·ç«¯è®¾ç½®
- **æ­¥éª¤1**ï¼š å‚è€ƒ [unitree_deploy/README.md](https://github.com/unitreerobotics/unifolm-world-model-action/blob/main/unitree_deploy/README.md)ï¼Œåˆ›å»º ```unitree_deploy``` conda ç¯å¢ƒï¼Œå®‰è£…æ‰€éœ€ä¾èµ–åŒ…ï¼Œå¹¶åœ¨çœŸå®æœºå™¨äººç«¯å¯åŠ¨æ§åˆ¶å™¨æˆ–æœåŠ¡;
- **æ­¥éª¤2**: æ‰“å¼€ä¸€ä¸ªæ–°çš„ç»ˆç«¯ï¼Œä»å®¢æˆ·ç«¯åˆ°æœåŠ¡å™¨å»ºç«‹éš§é“è¿æ¥ï¼š
```
ssh user_name@remote_server_IP -CNg -L 8000:127.0.0.1:8000
```
- **æ­¥éª¤3**ï¼š è¿è¡Œ ```unitree_deploy/robot_client.py``` è„šæœ¬ä»¥å¯åŠ¨æ¨ç†ï¼š
```
cd unitree_deploy
python scripts/robot_client.py --robot_type "g1_dex1" --action_horizon 16 --exe_steps 16 --observation_horizon 2 --language_instruction "pack black camera into box" --output_dir ./results --control_freq 15
```

## ğŸ“ ä»£ç æ¶æ„
ä»¥ä¸‹æ˜¯æœ¬é¡¹ç›®ä»£ç ç»“æ„è®¾è®¡åŠæ ¸å¿ƒç»„ä»¶è¯´æ˜ï¼šï¼š
```
unitree-world-model/
    â”œâ”€â”€ assets                      # GIFåŠ¨å›¾ã€é™æ€å›¾ç‰‡å’Œæ¼”ç¤ºè§†é¢‘ç­‰åª’ä½“ç´ æ
    â”œâ”€â”€ configs                     # é…ç½®æ–‡ä»¶
    â”‚    â”œâ”€â”€ inference
    â”‚    â””â”€â”€  train
    â”œâ”€â”€ examples                    # ç¤ºä¾‹æ•°æ®
    â”œâ”€â”€ external                    # å¤–éƒ¨ä»£ç åº“
    â”œâ”€â”€ prepare_data                # æ•°æ®å¤„ç†
    â”œâ”€â”€ scripts                     # ä¸»ç¨‹åºè„šæœ¬
    â”œâ”€â”€ src
    â”‚    â”œâ”€â”€unitree_worldmodel      # æ ¸å¿ƒåº“
    â”‚    â”‚      â”œâ”€â”€ data            # æ•°æ®åŠ è½½
    â”‚    â”‚      â”œâ”€â”€ models          # æ¨¡å‹æ¶æ„
    â”‚    â”‚      â”œâ”€â”€ modules         # è‡ªå®šä¹‰æ¨¡å—
    |    â”‚      â””â”€â”€  utils          # å·¥å…·å‡½æ•°
```

## ğŸ™ è‡´è°¢å£°æ˜
æœ¬é¡¹ç›®ä»£ç åŸºäºä»¥ä¸‹ä¼˜ç§€å¼€æºé¡¹ç›®æ„å»ºï¼Œç‰¹æ­¤è‡´è°¢ï¼š[DynamiCrafter](https://github.com/Doubiiu/DynamiCrafter), [Diffusion Policy](https://github.com/real-stanford/diffusion_policy), [ACT](https://github.com/MarkFzp/act-plus-plus) å’Œ [HPT](https://github.com/liruiw/HPT).
